{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What drives the price of a car?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the goal of this project is to find a number of metrics that drive customers to purchase cars. Our client is going to be a used car dealership, so we want to generate a number of factors that are important to the price of used cars. The data is provided so there is no need to acquire data. This project will likely involve cleaning and preparing the dataset, then proceeding to create regression models to find the key drivers of used car prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, I need to get a sense of the dataset, including whether the data is numeric or not. I need to analyse the dataset and perform any data cleaning to ensure that the data we have is useable in our future models. This begins with an understanding of the dataset. I'll start by loading the data and looking at a header to get a sense of what I'm dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/vehicles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>region</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>condition</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>fuel</th>\n",
       "      <th>odometer</th>\n",
       "      <th>title_status</th>\n",
       "      <th>transmission</th>\n",
       "      <th>VIN</th>\n",
       "      <th>drive</th>\n",
       "      <th>size</th>\n",
       "      <th>type</th>\n",
       "      <th>paint_color</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>7305672709</td>\n",
       "      <td>auburn</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>express cargo van</td>\n",
       "      <td>like new</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>68472.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>1GCWGAFP8J1309579</td>\n",
       "      <td>rwd</td>\n",
       "      <td>full-size</td>\n",
       "      <td>van</td>\n",
       "      <td>white</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>7305672266</td>\n",
       "      <td>auburn</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>express cargo van</td>\n",
       "      <td>like new</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>69125.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>1GCWGAFP4K1214373</td>\n",
       "      <td>rwd</td>\n",
       "      <td>full-size</td>\n",
       "      <td>van</td>\n",
       "      <td>white</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>7305672252</td>\n",
       "      <td>auburn</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>express cargo van</td>\n",
       "      <td>like new</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>66555.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>1GCWGAFPXJ1337903</td>\n",
       "      <td>rwd</td>\n",
       "      <td>full-size</td>\n",
       "      <td>van</td>\n",
       "      <td>white</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>7316482063</td>\n",
       "      <td>birmingham</td>\n",
       "      <td>4000</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>toyota</td>\n",
       "      <td>echo</td>\n",
       "      <td>excellent</td>\n",
       "      <td>4 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>JTDBT123520243495</td>\n",
       "      <td>fwd</td>\n",
       "      <td>compact</td>\n",
       "      <td>sedan</td>\n",
       "      <td>blue</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>7316429417</td>\n",
       "      <td>birmingham</td>\n",
       "      <td>2500</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>bmw</td>\n",
       "      <td>525i</td>\n",
       "      <td>fair</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>110661.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>WBAHD6322SGK86772</td>\n",
       "      <td>rwd</td>\n",
       "      <td>mid-size</td>\n",
       "      <td>sedan</td>\n",
       "      <td>white</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id      region  price    year manufacturer              model  \\\n",
       "126  7305672709      auburn      0  2018.0    chevrolet  express cargo van   \n",
       "127  7305672266      auburn      0  2019.0    chevrolet  express cargo van   \n",
       "128  7305672252      auburn      0  2018.0    chevrolet  express cargo van   \n",
       "215  7316482063  birmingham   4000  2002.0       toyota               echo   \n",
       "219  7316429417  birmingham   2500  1995.0          bmw               525i   \n",
       "\n",
       "     condition    cylinders fuel  odometer title_status transmission  \\\n",
       "126   like new  6 cylinders  gas   68472.0        clean    automatic   \n",
       "127   like new  6 cylinders  gas   69125.0        clean    automatic   \n",
       "128   like new  6 cylinders  gas   66555.0        clean    automatic   \n",
       "215  excellent  4 cylinders  gas  155000.0        clean    automatic   \n",
       "219       fair  6 cylinders  gas  110661.0        clean    automatic   \n",
       "\n",
       "                   VIN drive       size   type paint_color state  \n",
       "126  1GCWGAFP8J1309579   rwd  full-size    van       white    al  \n",
       "127  1GCWGAFP4K1214373   rwd  full-size    van       white    al  \n",
       "128  1GCWGAFPXJ1337903   rwd  full-size    van       white    al  \n",
       "215  JTDBT123520243495   fwd    compact  sedan        blue    al  \n",
       "219  WBAHD6322SGK86772   rwd   mid-size  sedan       white    al  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can already see some redundant data and some irrelevant data. I dropped all null values in the header so that I could see what types of data I had, but since the index does not start at 1 after the drop, there is an issue of null/blank values. \n",
    "\n",
    "Some of this data is also not relevant, like the VIN numbers. The VIN numbers do contain some info in them, but they are unique to each car and too heavily formatted to be easily parsed for my model. This means that I am going to need to drop some columns and some rows to get a clean dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to know how many null values I have in this dataset, so I will check the non-null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 426880 entries, 0 to 426879\n",
      "Data columns (total 18 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id            426880 non-null  int64  \n",
      " 1   region        426880 non-null  object \n",
      " 2   price         426880 non-null  int64  \n",
      " 3   year          425675 non-null  float64\n",
      " 4   manufacturer  409234 non-null  object \n",
      " 5   model         421603 non-null  object \n",
      " 6   condition     252776 non-null  object \n",
      " 7   cylinders     249202 non-null  object \n",
      " 8   fuel          423867 non-null  object \n",
      " 9   odometer      422480 non-null  float64\n",
      " 10  title_status  418638 non-null  object \n",
      " 11  transmission  424324 non-null  object \n",
      " 12  VIN           265838 non-null  object \n",
      " 13  drive         296313 non-null  object \n",
      " 14  size          120519 non-null  object \n",
      " 15  type          334022 non-null  object \n",
      " 16  paint_color   296677 non-null  object \n",
      " 17  state         426880 non-null  object \n",
      "dtypes: float64(2), int64(2), object(14)\n",
      "memory usage: 58.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant amount of empty cells, and this might compromise my dataset. I am going to do some testing to see what I can drop to get a cleaner dataset. My goal is to keep around 50% of the rows from my cleaning to ensure my analysis is robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Remaining rows after drop 8.17%\n"
     ]
    }
   ],
   "source": [
    "# Testing a naive approach and dropping all null values.\n",
    "drop_rows_data = data.dropna()\n",
    "drop_percent = round(drop_rows_data.shape[0]/data.shape[0]*100, 2)\n",
    "print(f\"\\nRemaining rows after drop {drop_percent}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the rows with null values leaves only 8% of the data remaining. This is far too significant of a loss of data, so I'll try and drop columns before we drop the rows. I will drop the columns that I think are unrelated or redundant first. After that, I will remove columns by ordering them by how much of their data is null or NaN and rmeoving them in order. I will stop when the data is near or above 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Remaining rows after drop 48.59%\n"
     ]
    }
   ],
   "source": [
    "# Testing adding columns by how much data they are missing.\n",
    "drop_columns = data.drop(['size', 'cylinders', 'VIN', 'state', 'region', 'model', 'condition', 'id'], axis = 1).dropna()\n",
    "drop_percent2 = round(drop_columns.shape[0]/data.shape[0]*100, 2)\n",
    "print(f\"\\nRemaining rows after drop {drop_percent2}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally I have a dataset that is large enough to perform robust analysis. At this point, I am ready to prepare the data for preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the \"drop columns\" dataset that I saved from the previous step as my basis for my data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>fuel</th>\n",
       "      <th>odometer</th>\n",
       "      <th>title_status</th>\n",
       "      <th>transmission</th>\n",
       "      <th>drive</th>\n",
       "      <th>type</th>\n",
       "      <th>paint_color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>gas</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>rwd</td>\n",
       "      <td>truck</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27990</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>gmc</td>\n",
       "      <td>gas</td>\n",
       "      <td>68696.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>4wd</td>\n",
       "      <td>pickup</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34590</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>gas</td>\n",
       "      <td>29499.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>4wd</td>\n",
       "      <td>pickup</td>\n",
       "      <td>silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>toyota</td>\n",
       "      <td>gas</td>\n",
       "      <td>43000.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>4wd</td>\n",
       "      <td>truck</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29990</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>gas</td>\n",
       "      <td>17302.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>4wd</td>\n",
       "      <td>pickup</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price    year manufacturer fuel  odometer title_status transmission drive  \\\n",
       "0  15000  2013.0         ford  gas  128000.0        clean    automatic   rwd   \n",
       "1  27990  2012.0          gmc  gas   68696.0        clean        other   4wd   \n",
       "2  34590  2016.0    chevrolet  gas   29499.0        clean        other   4wd   \n",
       "3  35000  2019.0       toyota  gas   43000.0        clean    automatic   4wd   \n",
       "4  29990  2016.0    chevrolet  gas   17302.0        clean        other   4wd   \n",
       "\n",
       "     type paint_color  \n",
       "0   truck       black  \n",
       "1  pickup       black  \n",
       "2  pickup      silver  \n",
       "3   truck        grey  \n",
       "4  pickup         red  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resetting index and displaying a header to analyze next steps\n",
    "drop_columns = drop_columns.reset_index(drop = True)\n",
    "drop_columns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to perform any steps to get the data into a form that is ready for modeling. The most important of which is to ensure that my data is readable by my models. Looking at the data, I have two problems that need to be solved: the nominal data needs to be numeric, and the numeric data is not standardized. I will use a one hot encoding strategy on the non-numeric columns to prepare them for modeling. For the remaining numeric data, I will scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I need to separate the target feature and the remaining features into new temporary dataframes.\n",
    "temp_X = drop_columns.drop(['price'], axis = 1)\n",
    "temp_y = drop_columns['price']\n",
    "\n",
    "# First I split the data that is being scaled and the data that is being one hot encoded.\n",
    "numeric_X = temp_X[['odometer', 'year']]                       # This data needs will be scaled\n",
    "nominal_X = temp_X.drop(['odometer', 'year'], axis = 1)        # This data will be encoded\n",
    "\n",
    "# Now I scale the numeric data\n",
    "scaled_X = (numeric_X - numeric_X.mean())/(numeric_X.std())\n",
    "y = (y - y.mean())/(y.std())\n",
    "\n",
    "# Next I need to use a one hot encoding strategy on the nominal data\n",
    "encoded_X = pd.get_dummies(nominal_X)\n",
    "\n",
    "# Now, I merge the encoded and scaled data back together to form one dataframe\n",
    "X = pd.concat([scaled_X, encoded_X], axis = 1)\n",
    "\n",
    "# Finally I'm going to split the data into train and test sets, in anticipation of modeling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have my data prepared for modeling. The dataset is numeric, and the continuous features are scaled. Note that the data is largely binary, with high dimensionality. This means that a feature reduction or linear combination of features would not be advisable. I can still perform reductions in the models, but this may cause more features to be dropped from analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "With your (almost?) final dataset in hand, it is now time to build some models.  Here, you should build a number of different regression models with the price as the target.  In building your models, you should explore different parameters and be sure to cross-validate your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, I run a simple linear regression on the data to get a baseline for future models and to get a better sense of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.12013834308653984\n",
      "Test MSE: 3.052925210219233\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "train_mse = mean_squared_error(model.predict(X_train), y_train)\n",
    "test_mse = mean_squared_error(model.predict(X_test), y_test)\n",
    "\n",
    "print(f\"Train MSE: {train_mse}\")\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple linear regression model performed much better on the test mse and gives us a baseline of what is happening with the models. The data has a large number of features, so this would be a good time to do a Sequential Feature Selection to reduce the dimensionality and pull out a small number of features that are most improtant to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SequentialFeatureSelector(estimator = LinearRegression(), n_features_to_select=6, cv = 5)\n",
    "best_features = selector.fit_transform(X, y)\n",
    "best_features_df = pd.DataFrame(best_features, columns = selector.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manufacturer_aston-martin</th>\n",
       "      <th>manufacturer_datsun</th>\n",
       "      <th>manufacturer_ferrari</th>\n",
       "      <th>manufacturer_harley-davidson</th>\n",
       "      <th>manufacturer_land rover</th>\n",
       "      <th>manufacturer_morgan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   manufacturer_aston-martin  manufacturer_datsun  manufacturer_ferrari  \\\n",
       "0                        0.0                  0.0                   0.0   \n",
       "1                        0.0                  0.0                   0.0   \n",
       "2                        0.0                  0.0                   0.0   \n",
       "3                        0.0                  0.0                   0.0   \n",
       "4                        0.0                  0.0                   0.0   \n",
       "\n",
       "   manufacturer_harley-davidson  manufacturer_land rover  manufacturer_morgan  \n",
       "0                           0.0                      0.0                  0.0  \n",
       "1                           0.0                      0.0                  0.0  \n",
       "2                           0.0                      0.0                  0.0  \n",
       "3                           0.0                      0.0                  0.0  \n",
       "4                           0.0                      0.0                  0.0  "
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will apply the train and test data to the model and see how it performs in a linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.12013834308653984\n",
      "Test MSE: 3.052925210219233\n"
     ]
    }
   ],
   "source": [
    "# Here is a simple linear regression on the selected features\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "train_mse = mean_squared_error(linreg.predict(X_train), y_train)\n",
    "test_mse = mean_squared_error(linreg.predict(X_test), y_test)\n",
    "print(f\"Train MSE: {train_mse}\")\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next model, I will use GridSearchCV to optimize hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV with Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model, I want to use a GridSearchCV to optimize hyperparameters. In this case, I want to find the best alpha value for my ridge regression. I am using the default 5-fold cross validation in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ridge__alpha': 1}\n",
      "Train MSE: 1.3685110667947205\n",
      "Test MSE: 0.25180959459527064\n"
     ]
    }
   ],
   "source": [
    "# I will test three alpha values for this model.\n",
    "ridge_param_dict = {'ridge__alpha': [1, 0.1, 10]}\n",
    "ridge_pipe = Pipeline([('ridge', Ridge())])\n",
    "ridge_grid = GridSearchCV(ridge_pipe, param_grid= ridge_param_dict).fit(X_train, y_train)\n",
    "\n",
    "# Now that I have a fit pipeline, I will extract the best model from the pipeline and calculate some descriptive charecteristics\n",
    "best_estimator = ridge_grid.best_estimator_\n",
    "best_selector = best_estimator.named_steps['ridge']\n",
    "best_model = best_estimator.named_steps['ridge']\n",
    "best_params = ridge_grid.best_params_\n",
    "\n",
    "GS_train_mse = mean_squared_error(best_model.predict(X_train), y_train)\n",
    "GS_test_mse = mean_squared_error(best_model.predict(X_test), y_test)\n",
    "\n",
    "# Here I will print out some data so that I can analyze the results.\n",
    "print(best_params)\n",
    "#print(best_estimator[:-1].get_feature_names_out(X_train))\n",
    "print(f\"Train MSE: {GS_train_mse}\")\n",
    "print(f\"Test MSE: {GS_test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, I now know the optimal alpha is 1, which is the default for GridSearchCV. Now I will build a model to find the optimal number of features with the best alpha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV for SFS hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'selector__n_features_to_select': 3}\n",
      "Index(['manufacturer_aston-martin', 'manufacturer_ferrari',\n",
      "       'manufacturer_morgan'],\n",
      "      dtype='object')\n",
      "Train MSE: 1.3685110717611002\n",
      "Test MSE: 0.25180959861813135\n"
     ]
    }
   ],
   "source": [
    "#I will test for the optimal number of features selected\n",
    "selector_pipe = Pipeline([('selector', SequentialFeatureSelector(LinearRegression())),\n",
    "                         ('ridge', Ridge())])\n",
    "param_dict = {'selector__n_features_to_select': [2, 3, 4]}\n",
    "selector_grid = GridSearchCV(selector_pipe, param_grid = param_dict).fit(X_train, y_train)\n",
    "\n",
    "#Now i will calculate some descriptive variables to better understand the results.\n",
    "best_estimator = selector_grid.best_estimator_\n",
    "best_selector = best_estimator.named_steps['selector']\n",
    "best_model = best_estimator.named_steps['ridge']\n",
    "best_params = selector_grid.best_params_\n",
    "feature_names = X_train.columns[best_selector.get_support()]\n",
    "\n",
    "selector_train_mse = mean_squared_error(selector_grid.predict(X_train), y_train)\n",
    "selector_test_mse = mean_squared_error(selector_grid.predict(X_test), y_test)\n",
    "\n",
    "print(best_params)\n",
    "print(feature_names)\n",
    "print(f'Train MSE: {selector_train_mse}')\n",
    "print(f'Test MSE: {selector_test_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this model, we have found the optimal hyperparameters and the optimal columns for the regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "With some modeling accomplished, we aim to reflect on what we identify as a high quality model and what we are able to learn from this.  We should review our business objective and explore how well we can provide meaningful insight on drivers of used car prices.  Your goal now is to distill your findings and determine whether the earlier phases need revisitation and adjustment or if you have information of value to bring back to your client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results of these models, there is a clear pattern of overfitting. The train MSE is consistently much higher than the test MSE. Having a low test MSE is good, but the difference is massive. There is also the issue that the MSE for each model is too similar. I think this is due to the same train/test split being used, but with further testing I've found that there is alot of variance depending on the split of the data. This high variance reinforces my idea that overfitting is biasing the results.\n",
    "\n",
    "This means that further testing could be applied to potentially further reduce the overfitting and produce a more accurate model. In this case, we can still perform analysis on the moels and see what can be learned. The models were able to achieve a low MSE which means they were able to predict the price fairly well form the features. Since the data is normalized and it has high dimensionality, it would be difficult to look at a table of coefficients and find which factors are the most important. Instead, I noticed that every feature selection program found that the best predictors of price were all encodings of the \"manufacturer\" column. This follows common sense, as it is commonly known that manufacturers like Aston-Martin and Ferrari produce luxury cars that cost orders of magnitude more than brands like Fords.\n",
    "\n",
    "Combining the overfitting of the model, and the consistent selection of \"manufacturer\" features, we can conclude that this model does not bring a lot of valuable information to the client. We can safely say that the manufacturer is vital for determining price, but this model is not going to bring any deeper insights beyond that. Potentially revisiting the data nds olving the overfitting problem could bring more useful insights. Removing the manufacturer column and adding back some other columns may provide a more unique insight tha tmay be less apparent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "\n",
    "Now that we've settled on our models and findings, it is time to deliver the information to the client.  You should organize your work as a basic report that details your primary findings.  Keep in mind that your audience is a group of used car dealers interested in fine tuning their inventory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, I would say that the most important factor in my car pricing model is the Manufacturer. Other details like age and mileage don't compare in importance to the manufacturer of the car. This model has shown that the dealer would do well to rely on brand recognition, and to price their cars according to the manufacturer. Also note that this model is not infallible, and even though the model has shown the value of the manufacturer in determining price, there is a limit to what a computer model can predict, and a dealer should use their best judgement on pricing. This information is limited by the dataset, which may not encompass the reality of cars sold on a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
